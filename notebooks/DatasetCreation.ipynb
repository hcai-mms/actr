{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oF3Ck7RI9G2l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from paths.paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egPRnCg6cO9S"
   },
   "source": [
    "# Prepare data (10-core filtering) and temporal split into train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLeAh3T1HBiD"
   },
   "outputs": [],
   "source": [
    "data_path = f'{BASE_FOLDER}/actr_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VruDs5Pv9VW5"
   },
   "outputs": [],
   "source": [
    "FULL_EVENTS_PATH = f'{data_path}/listening_events.tsv.bz2'\n",
    "counts_columns = ['user_id', 'track_id', 'album_id', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bq59b8fJ9VQZ"
   },
   "outputs": [],
   "source": [
    "listening_events = pd.read_csv(FULL_EVENTS_PATH, sep='\\t', usecols=['user_id', 'track_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3751,
     "status": "ok",
     "timestamp": 1680200932167,
     "user": {
      "displayName": "Marta Christian",
      "userId": "04692417801997828083"
     },
     "user_tz": -120
    },
    "id": "2e0Kwbc1Vs-s",
    "outputId": "9ca2ac76-3dd8-4861-e7f8-3d2cffab0651"
   },
   "outputs": [],
   "source": [
    "# select only the last month\n",
    "listening_events_ = listening_events[listening_events['timestamp'] > '2020-02-19']\n",
    "\n",
    "# remove users that listened to more tracks than 99% of the users (radio-stations)\n",
    "users = listening_events_.groupby(['user_id']).count().reset_index().sort_values(by='track_id')\n",
    "quant = listening_events_.groupby(['user_id']).count().reset_index()['track_id'].quantile(q=0.99)\n",
    "normal_users = users[users['track_id'] < quant]['user_id'].values.tolist()\n",
    "listening_events_filtered = listening_events_[listening_events_['user_id'].isin(normal_users)]\n",
    "listening_events = listening_events_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2_oYoByVuvF"
   },
   "outputs": [],
   "source": [
    "tracks_5_users_listening_events = listening_events.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17784,
     "status": "ok",
     "timestamp": 1680200950549,
     "user": {
      "displayName": "Marta Christian",
      "userId": "04692417801997828083"
     },
     "user_tz": -120
    },
    "id": "oY4ZTrYY9VDc",
    "outputId": "253fc357-7265-4182-adc8-c27495135d96"
   },
   "outputs": [],
   "source": [
    "# Select only users with at least 10 interactions. In the end, we want to achieve 10-core filtering. \n",
    "# This way, we are sure that there are listening events in the train, val, and test sets.\n",
    "# This needs to be iterated until there are no items with less than 10 users and no users with less than 10 LE\n",
    "\n",
    "users_thresh = 10\n",
    "tracks_thresh = 10\n",
    "\n",
    "# Set the initial number of cold users, i.e. users with less than users_thresh listening events\n",
    "cold_users = (listening_events.user_id.value_counts() < users_thresh).sum()\n",
    "\n",
    "# Repeat until there are no cold users\n",
    "while cold_users > 0:\n",
    "    # print(cold_users)\n",
    "    # Get the unique ids of users with more than users_thresh LE\n",
    "    core_users_series = tracks_5_users_listening_events.user_id.value_counts()\n",
    "    core_users_series = core_users_series[core_users_series > users_thresh]\n",
    "    core_users = set(core_users_series.index.unique())\n",
    "    \n",
    "    # restrict to those users\n",
    "    core_5_listening_events = tracks_5_users_listening_events[tracks_5_users_listening_events.user_id.isin(core_users)]\n",
    "    \n",
    "    # get the number of unique listeners of each track\n",
    "    gb = core_5_listening_events.groupby(['track_id', 'user_id']).size()\n",
    "    gb = gb.reset_index()\n",
    "    gb_tracks = gb.groupby(['track_id']).size()\n",
    "\n",
    "    # Select tracks that have at least tracks_thresh unique listeners\n",
    "    tracks_5_users = set(gb_tracks[gb_tracks >= tracks_thresh].index.unique())\n",
    "    tracks_5_users_listening_events = core_5_listening_events[core_5_listening_events.track_id.isin(tracks_5_users)]\n",
    "    \n",
    "    # Recompute the number of cold users\n",
    "    cold_users = (tracks_5_users_listening_events.user_id.value_counts() < users_thresh).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1689,
     "status": "ok",
     "timestamp": 1680200952234,
     "user": {
      "displayName": "Marta Christian",
      "userId": "04692417801997828083"
     },
     "user_tz": -120
    },
    "id": "lxHIE3Jx9U70",
    "outputId": "a73eb3a4-f7a2-4774-868e-859fe74edf5d"
   },
   "outputs": [],
   "source": [
    "# Convert the timestamp to a \n",
    "tracks_5_users_listening_events.timestamp = pd.to_datetime(tracks_5_users_listening_events.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97389,
     "status": "ok",
     "timestamp": 1680201049610,
     "user": {
      "displayName": "Marta Christian",
      "userId": "04692417801997828083"
     },
     "user_tz": -120
    },
    "id": "H8qyCwm3-EWZ",
    "outputId": "d90f5d70-ade8-4af0-8c42-e944c4b14a79"
   },
   "outputs": [],
   "source": [
    "# Temporal splitting into train test val\n",
    "# - Train 60% [first portion]\n",
    "# - Val 20%   [mid portion]\n",
    "# - Test 20%  [last portion]\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "# Iterate over selected users\n",
    "for user in tqdm(tracks_5_users_listening_events.user_id.unique()):\n",
    "    # Get the LE of the current user, sorted by timestamp\n",
    "    user_df = tracks_5_users_listening_events[tracks_5_users_listening_events.user_id==user].sort_values(by=['timestamp'])\n",
    "    user_df = user_df.reset_index(drop=True)\n",
    "    user_interactions = len(user_df)\n",
    "    \n",
    "    \n",
    "    test = user_df\n",
    "    n_test_int = user_interactions // 5\n",
    "    \n",
    "    # Split the LE of the user. \n",
    "    # Train is used for user similarity, and training and validation of VAE, GRU4Rec, BPR\n",
    "    # Val is used for hyperparam selection\n",
    "    # Test is using for the evaluation protocol (rolling session completion)\n",
    "    train, val, test = user_df[:-2 * n_test_int], user_df[-2 * n_test_int:-n_test_int], user_df[-n_test_int:]\n",
    "    train_list += [train]\n",
    "    val_list += [val]\n",
    "    test_list += [test]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "938Yx34kOeeL"
   },
   "outputs": [],
   "source": [
    "# Concatenate all users\n",
    "train = pd.concat(train_list)\n",
    "val = pd.concat(val_list)\n",
    "test = pd.concat(test_list)\n",
    "# Convert the timestamp in the training set to seconds and remove useless zeros \n",
    "train['timestamp'] = train.timestamp.values.astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_EjpZJqVrvw"
   },
   "source": [
    "# Train set handling\n",
    "We do the following:\n",
    " 1. Binarize the training set\n",
    " 2. Select unique (user, item) pairs with a threshold of 1\n",
    " 3. Select users that listened to at least 6 unique tracks\n",
    " 4. Select corresponding items\n",
    " 5. Filter the non-binarized training set on these sets of users and items\n",
    "The rest of the splitting for GRU4Rec, MultVAE and BPR is done by RecBole.\n",
    "\n",
    "Temporal for GRU4Rec, random for MultVAE and BPR (on the binarized version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1557,
     "status": "ok",
     "timestamp": 1680201187417,
     "user": {
      "displayName": "Marta Christian",
      "userId": "04692417801997828083"
     },
     "user_tz": -120
    },
    "id": "l2Jv-nE148so",
    "outputId": "c7e38b47-b52d-4a87-b0f0-af59ff3556a7"
   },
   "outputs": [],
   "source": [
    "binarization_threshold = 0\n",
    "playcounts_df = train.groupby(['user_id', 'track_id']).count().reset_index()\n",
    "binarized_df = playcounts_df[playcounts_df.timestamp > binarization_threshold].reset_index(drop=True)\n",
    "binarized_df.timestamp = 1\n",
    "# This is the group of users that have at least 6 binarized LE in the training set (used for BPR and VAE) \n",
    "group = binarized_df.groupby(['user_id'])['track_id'].count().reset_index()\n",
    "group = group[group['track_id'] > 5]\n",
    "\n",
    "# For BPR and MultVAE\n",
    "users_above_threshold = list(group.user_id.unique())\n",
    "train_bin = binarized_df[binarized_df['user_id'].isin(users_above_threshold)]\n",
    "items_above_threshold = list(train_bin.track_id.unique())\n",
    "train_bin = train_bin[train_bin['track_id'].isin(items_above_threshold)]\n",
    "    \n",
    "# For GRU4Rec\n",
    "train_gru = train[train['user_id'].isin(users_above_threshold)]\n",
    "train_gru = train_gru[train_gru['track_id'].isin(items_above_threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tDDnJRcvo6a"
   },
   "outputs": [],
   "source": [
    "# Use RecBole column naming\n",
    "train_bin = binarized_df.rename(\n",
    "    columns={'user_id': 'user_id:token', 'track_id': 'item_id:token', 'timestamp': 'timestamp:float'})\n",
    "\n",
    "train_gru = train_gru.rename(\n",
    "    columns={'user_id': 'user_id:token', 'track_id': 'item_id:token', 'timestamp': 'timestamp:float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_bin.to_csv(data_path + '/actr_data_bin/actr_data_bin_2.inter', index=False, sep='\\t')\n",
    "# train_gru.to_csv(data_path + '/actr_data_gru/actr_data_gru_2.inter', index=False, sep='\\t')\n",
    "# val = val.rename(columns={'user_id': 'user_id:token', 'track_id': 'item_id:token', 'timestamp': 'timestamp:float'})\n",
    "# val.to_csv(data_path + '/actr_val_data/actr_val_data_2.inter', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF DATA PREPARATION\n",
    "Now go to FinalPrepareSpotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPDhH+t38ub3/x+4f0RDQ51",
   "mount_file_id": "1OfjpsAZai5z6sbP-f44XZLWjoQtqVHz9",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
